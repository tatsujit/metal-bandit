#+TITLE: MetalBandit User Manual
#+AUTHOR: Claude Code Assistant
#+DATE: 2025-07-04
#+STARTUP: overview
#+TOC: headlines 2

* Table of Contents :TOC:
- [[#introduction][Introduction]]
- [[#installation][Installation]]
- [[#quick-start-guide][Quick Start Guide]]
- [[#system-requirements][System Requirements]]
- [[#basic-usage][Basic Usage]]
- [[#advanced-usage][Advanced Usage]]
- [[#testing-guide][Testing Guide]]
- [[#performance-optimization][Performance Optimization]]
- [[#troubleshooting][Troubleshooting]]
- [[#api-reference][API Reference]]
- [[#examples-and-tutorials][Examples and Tutorials]]
- [[#best-practices][Best Practices]]

* Introduction

MetalBandit is a high-performance GPU-accelerated Bernoulli multi-armed bandit simulator implemented in Julia. It leverages Apple Silicon's Metal framework to achieve significant speedups in Q-learning simulations and Maximum Likelihood Estimation (MLE) parameter recovery.

** Key Features
- *GPU-Accelerated Q-Learning*: Softmax action selection with parallel agent updates
- *Ultra-Fast MLE Parameter Estimation*: Heavily optimized GPU kernels for parameter recovery
- *Bernoulli Bandit Environment*: Realistic bandit problem simulation
- *Parameter Recovery Analysis*: Comprehensive plotting and statistical analysis
- *Performance Benchmarking*: Detailed performance comparison and optimization
- *Batch Processing*: Memory-efficient processing for large-scale simulations

** Performance Highlights
- Up to 38.7x speedup over CPU implementations
- Throughput exceeding 900,000 operations per second
- Parameter recovery accuracy with RÂ² > 0.93
- Memory bandwidth utilization up to 28.57 GB/s

* Installation

** Prerequisites
- Julia 1.9 or later
- Apple Silicon Mac (M1/M2/M3 series)
- macOS with Metal support
- Minimum 8GB unified memory (16GB+ recommended for large problems)

** Package Installation

*** Method 1: Direct Installation
#+BEGIN_SRC julia
using Pkg
Pkg.add(["Metal", "Statistics", "BenchmarkTools", "Random", 
         "Plots", "StatsPlots", "Distributions", "LinearAlgebra"])
#+END_SRC

*** Method 2: Using Project Environment
#+BEGIN_SRC bash
cd metal-bandit
julia --project=.
#+END_SRC

#+BEGIN_SRC julia
using Pkg
Pkg.instantiate()  # Install all dependencies from Project.toml
#+END_SRC

** Verification
Test that Metal.jl is working correctly:
#+BEGIN_SRC julia
using Metal
println("Metal functional: ", Metal.functional())
#+END_SRC

If this returns ~true~, you're ready to use MetalBandit!

* Quick Start Guide

** 30-Second Demo
#+BEGIN_SRC julia
# Load the simulator
include("metal_bandit_simulator.jl")

# Run the demonstration
result = demonstrate_metal_bandit_simulator()
#+END_SRC

This will:
1. Create a bandit environment with 8 arms, 500 agents, and 2000 trials
2. Run GPU-accelerated Q-learning simulation
3. Perform MLE parameter estimation
4. Generate parameter recovery analysis plots
5. Display performance metrics

** First Custom Simulation
#+BEGIN_SRC julia
# Create environment: 5 arms, 1000 trials, 100 agents
env = MetalBernoulliEnvironment(5, 1000, 100)

# Create Q-learning agent with custom parameters
agent = MetalQLearningAgent(5, 100, 1000; alpha=0.1f0, beta=3.0f0)

# Run simulation
run_metal_bandit_simulation!(env, agent)

# Estimate parameters using GPU
estimated_params = gpu_mle_parameter_estimation(env, agent)

# Analyze results
true_params = Array(env.true_params)
recovery_plot, metrics = plot_parameter_recovery(true_params, estimated_params)

println("Recovery RÂ²: ", round(metrics.r_squared, digits=4))
display(recovery_plot)
#+END_SRC

* System Requirements

** Hardware Requirements
| Component | Minimum | Recommended |
|-----------+----------+-------------|
| CPU | Apple M1 | Apple M2/M3 |
| Memory | 8GB | 16GB+ |
| Storage | 1GB free | 5GB+ free |
| OS | macOS 12+ | macOS 13+ |

** Software Requirements
| Software | Version | Purpose |
|----------+---------+---------|
| Julia | 1.9+ | Runtime environment |
| Metal.jl | Latest | GPU acceleration |
| Plots.jl | Latest | Visualization |

** Performance Scaling
| Problem Size | Memory Usage | Recommended RAM |
|--------------+--------------+-----------------|
| 100 agents, 5 arms | ~50MB | 8GB |
| 500 agents, 10 arms | ~250MB | 16GB |
| 1000 agents, 20 arms | ~1GB | 32GB |

* Basic Usage

** Creating Environments

*** Default Environment
#+BEGIN_SRC julia
# Creates environment with random true parameters
env = MetalBernoulliEnvironment(n_arms, n_trials, n_agents)
#+END_SRC

*** Custom Parameters
#+BEGIN_SRC julia
# Specify exact true parameters
true_params = [0.2 0.5 0.8; 0.3 0.6 0.9]  # 2 arms, 3 agents
env = MetalBernoulliEnvironment(2, 1000, 3; true_params=true_params)
#+END_SRC

** Creating Agents

*** Basic Agent
#+BEGIN_SRC julia
agent = MetalQLearningAgent(n_arms, n_agents, n_trials)
#+END_SRC

*** Custom Learning Parameters
#+BEGIN_SRC julia
# alpha: learning rate (0.0-1.0)
# beta: exploration parameter (>0.0)
agent = MetalQLearningAgent(n_arms, n_agents, n_trials; 
                           alpha=0.05f0,  # Conservative learning
                           beta=5.0f0)    # High exploration
#+END_SRC

** Running Simulations

*** Basic Simulation
#+BEGIN_SRC julia
run_metal_bandit_simulation!(env, agent)
#+END_SRC

*** Batch Processing
#+BEGIN_SRC julia
# For memory-efficient processing of large problems
run_metal_bandit_simulation!(env, agent; batch_size=500)
#+END_SRC

** Parameter Estimation

*** Standard MLE
#+BEGIN_SRC julia
estimated_params = gpu_mle_parameter_estimation(env, agent)
#+END_SRC

*** Batch vs Non-Batch Comparison
#+BEGIN_SRC julia
# Batch processing (default, more memory efficient)
est_batch = gpu_mle_parameter_estimation(env, agent; use_batch_processing=true)

# Non-batch processing (potentially faster for small problems)
est_nobatch = gpu_mle_parameter_estimation(env, agent; use_batch_processing=false)
#+END_SRC

* Advanced Usage

** Custom Simulation Workflows

*** Multi-Configuration Analysis
#+BEGIN_SRC julia
configurations = [
    (n_arms=5, n_agents=100, alpha=0.1f0, beta=2.0f0),
    (n_arms=5, n_agents=100, alpha=0.05f0, beta=5.0f0),
    (n_arms=5, n_agents=100, alpha=0.2f0, beta=1.0f0)
]

results = []
for config in configurations
    env = MetalBernoulliEnvironment(config.n_arms, 1000, config.n_agents)
    agent = MetalQLearningAgent(config.n_arms, config.n_agents, 1000; 
                               alpha=config.alpha, beta=config.beta)
    
    # Time the simulation
    sim_time = @elapsed run_metal_bandit_simulation!(env, agent)
    est_time = @elapsed estimated_params = gpu_mle_parameter_estimation(env, agent)
    
    # Analyze recovery
    true_params = Array(env.true_params)
    metrics, _, _ = analyze_parameter_recovery(true_params, estimated_params)
    
    push!(results, (config=config, sim_time=sim_time, est_time=est_time, 
                   recovery=metrics.r_squared))
end

# Display results
for (i, result) in enumerate(results)
    println("Config $i: RÂ²=$(round(result.recovery, digits=3)), " *
            "Time=$(round(result.sim_time + result.est_time, digits=2))s")
end
#+END_SRC

*** Parameter Sensitivity Analysis
#+BEGIN_SRC julia
# Test different learning rates
alphas = [0.01f0, 0.05f0, 0.1f0, 0.2f0, 0.5f0]
recovery_scores = Float64[]

for alpha in alphas
    env = MetalBernoulliEnvironment(8, 2000, 200)
    agent = MetalQLearningAgent(8, 200, 2000; alpha=alpha, beta=2.0f0)
    
    run_metal_bandit_simulation!(env, agent)
    estimated_params = gpu_mle_parameter_estimation(env, agent)
    
    true_params = Array(env.true_params)
    metrics, _, _ = analyze_parameter_recovery(true_params, estimated_params)
    push!(recovery_scores, metrics.r_squared)
end

# Plot sensitivity
using Plots
plot(alphas, recovery_scores, marker=:circle, 
     xlabel="Learning Rate (Î±)", ylabel="Recovery RÂ²",
     title="Parameter Recovery vs Learning Rate")
#+END_SRC

** Performance Benchmarking

*** Custom Benchmark Suite
#+BEGIN_SRC julia
# Define problem sizes to test
problem_sizes = [
    (n_arms=5, n_agents=50, n_trials=500),
    (n_arms=10, n_agents=100, n_trials=1000),
    (n_arms=15, n_agents=200, n_trials=2000),
    (n_arms=20, n_agents=500, n_trials=5000)
]

benchmark_results = []
for (i, size) in enumerate(problem_sizes)
    println("Benchmarking configuration $i/$(length(problem_sizes))...")
    
    env = MetalBernoulliEnvironment(size.n_arms, size.n_trials, size.n_agents)
    agent = MetalQLearningAgent(size.n_arms, size.n_agents, size.n_trials)
    
    # Measure simulation time
    sim_time = @elapsed run_metal_bandit_simulation!(env, agent)
    
    # Measure MLE time
    mle_time = @elapsed estimated_params = gpu_mle_parameter_estimation(env, agent)
    
    # Calculate throughput
    total_ops = size.n_arms * size.n_agents * size.n_trials
    throughput = total_ops / (sim_time + mle_time)
    
    push!(benchmark_results, (
        size = size,
        sim_time = sim_time,
        mle_time = mle_time,
        total_time = sim_time + mle_time,
        throughput = throughput
    ))
end

# Display benchmark results
for (i, result) in enumerate(benchmark_results)
    s = result.size
    println("Config $i: $(s.n_arms)Ã—$(s.n_agents)Ã—$(s.n_trials)")
    println("  Simulation: $(round(result.sim_time, digits=2))s")
    println("  MLE: $(round(result.mle_time, digits=2))s")
    println("  Throughput: $(round(result.throughput, digits=0)) ops/s")
    println()
end
#+END_SRC

* Testing Guide

** Running All Tests
#+BEGIN_SRC bash
cd test
julia runtests.jl
#+END_SRC

Expected output:
#+BEGIN_EXAMPLE
ðŸš€ Starting MetalBandit Test Suite
==================================================
âœ… Environment Tests completed successfully
âœ… Agent Tests completed successfully  
âœ… Kernel Tests completed successfully
âœ… Integration Tests completed successfully
âœ… Performance Tests completed successfully
ðŸŽ‰ All tests passed!
#+END_EXAMPLE

** Running Individual Test Suites

*** Environment Tests Only
#+BEGIN_SRC bash
julia test/test_environment.jl
#+END_SRC

*** Agent Tests Only
#+BEGIN_SRC bash
julia test/test_agent.jl
#+END_SRC

*** Kernel Tests Only
#+BEGIN_SRC bash
julia test/test_kernels.jl
#+END_SRC

*** Integration Tests Only
#+BEGIN_SRC bash
julia test/test_integration.jl
#+END_SRC

*** Performance Tests Only
#+BEGIN_SRC bash
julia test/test_performance.jl
#+END_SRC

** Test Configuration

Tests automatically adapt to your system:
- *Metal Available*: All tests run including GPU kernels
- *Metal Unavailable*: CPU-only tests with appropriate fallbacks
- *Verbose Mode*: System information and detailed metrics
- *Performance Tests*: Configurable stress test parameters

** Writing Custom Tests

*** Basic Test Structure
#+BEGIN_SRC julia
using Test
include("../metal_bandit_simulator.jl")

@testset "My Custom Tests" begin
    @testset "Custom Environment Test" begin
        env = MetalBernoulliEnvironment(3, 100, 10)
        @test env.n_arms == 3
        @test env.n_trials == 100
        @test env.n_agents == 10
    end
    
    @testset "Custom Performance Test" begin
        env = MetalBernoulliEnvironment(5, 500, 50)
        agent = MetalQLearningAgent(5, 50, 500)
        
        time_taken = @elapsed run_metal_bandit_simulation!(env, agent)
        @test time_taken < 10.0  # Should complete within 10 seconds
    end
end
#+END_SRC

* Performance Optimization

** Problem Size Guidelines

*** Small Problems (Development/Testing)
- *Agents*: 10-100
- *Arms*: 2-10  
- *Trials*: 100-1000
- *Expected Performance*: 10,000-100,000 ops/sec

*** Medium Problems (Research)
- *Agents*: 100-500
- *Arms*: 5-20
- *Trials*: 1000-5000  
- *Expected Performance*: 100,000-500,000 ops/sec

*** Large Problems (Production)
- *Agents*: 500-2000
- *Arms*: 10-50
- *Trials*: 5000-20000
- *Expected Performance*: 500,000-1,000,000+ ops/sec

** Memory Optimization

*** Batch Size Tuning
#+BEGIN_SRC julia
# For memory-constrained systems
run_metal_bandit_simulation!(env, agent; batch_size=100)

# For systems with ample memory  
run_metal_bandit_simulation!(env, agent; batch_size=2000)
#+END_SRC

*** Data Type Optimization
#+BEGIN_SRC julia
# Use Float32 for better GPU performance
true_params = rand(Float32, n_arms, n_agents)  # Not Float64

# Custom environment with optimized types
env = MetalBernoulliEnvironment(n_arms, n_trials, n_agents; 
                               true_params=Float32.(custom_params))
#+END_SRC

** GPU Utilization Tips

*** Maximize Parallel Work
- Use multiple agents rather than sequential processing
- Prefer larger batch sizes when memory allows
- Process multiple problem instances in parallel

*** Minimize CPU-GPU Transfers
#+BEGIN_SRC julia
# Good: Keep data on GPU
estimated_params = gpu_mle_parameter_estimation(env, agent)
final_analysis = analyze_parameter_recovery(Array(env.true_params), estimated_params)

# Avoid: Frequent GPU-CPU transfers in loops
# Don't repeatedly call Array() on GPU arrays in tight loops
#+END_SRC

* Troubleshooting

** Common Issues and Solutions

*** Metal Not Available
*Problem*: Metal.functional() returns false

*Solutions*:
1. Verify you're on Apple Silicon Mac
2. Check macOS version (requires 12+)
3. Update Metal.jl: ~Pkg.update("Metal")~
4. Restart Julia session

*Fallback*: Use CPU-only functions from original implementation

*** Memory Errors
*Problem*: GPU out of memory errors

*Solutions*:
1. Reduce batch size: ~batch_size=100~
2. Reduce problem size temporarily
3. Use Float32 instead of Float64
4. Close other GPU-intensive applications

*** Performance Issues
*Problem*: Slower than expected performance

*Diagnostics*:
#+BEGIN_SRC julia
# Check Metal functionality
println("Metal functional: ", Metal.functional())

# Monitor memory usage
println("Available memory: ", Sys.free_memory() Ã· 1024^2, " MB")

# Profile critical sections
using BenchmarkTools
@benchmark run_metal_bandit_simulation!(env, agent)
#+END_SRC

*Solutions*:
1. Increase problem size (GPU efficiency improves with larger problems)
2. Adjust batch size
3. Close background applications
4. Restart Julia to clear GPU memory

*** Type Errors
*Problem*: Type mismatch errors in analysis functions

*Solution*:
#+BEGIN_SRC julia
# Ensure consistent types
true_params = Float32.(Array(env.true_params))
estimated_params = Float32.(estimated_params)
metrics = analyze_parameter_recovery(true_params, estimated_params)
#+END_SRC

** Debugging Techniques

*** Enable Verbose Output
#+BEGIN_SRC julia
# Run with detailed output
ENV["JULIA_DEBUG"] = "Metal"
include("metal_bandit_simulator.jl")
#+END_SRC

*** Check GPU Status
#+BEGIN_SRC julia
using Metal
println("Metal functional: ", Metal.functional())
if Metal.functional()
    # Test basic operations
    a = Metal.ones(Float32, 100, 100)
    b = Metal.zeros(Float32, 100, 100)  
    c = a + b
    println("Basic GPU operations working: ", all(Array(c) .â‰ˆ 1.0f0))
end
#+END_SRC

*** Minimal Working Example
#+BEGIN_SRC julia
# Test with smallest possible problem
try
    env = MetalBernoulliEnvironment(2, 10, 5)
    agent = MetalQLearningAgent(2, 5, 10)
    run_metal_bandit_simulation!(env, agent)
    estimated_params = gpu_mle_parameter_estimation(env, agent)
    println("Minimal test successful!")
catch e
    println("Error in minimal test: ", e)
end
#+END_SRC

* API Reference

** Core Types

*** MetalBernoulliEnvironment
#+BEGIN_SRC julia
MetalBernoulliEnvironment(n_arms::Int, n_trials::Int, n_agents::Int; 
                         true_params::Union{Nothing, Array{T, 2}} = nothing)
#+END_SRC

*Fields*:
- ~n_arms~: Number of bandit arms
- ~n_trials~: Number of trials per agent
- ~n_agents~: Number of parallel agents
- ~true_params~: True reward probabilities (n_arms Ã— n_agents)
- ~rewards~, ~actions~, ~actual_rewards~: Simulation results

*** MetalQLearningAgent  
#+BEGIN_SRC julia
MetalQLearningAgent(n_arms::Int, n_agents::Int, n_trials::Int;
                   alpha::T = 0.1f0, beta::T = 2.0f0)
#+END_SRC

*Fields*:
- ~alpha~: Learning rate (0.0-1.0)
- ~beta~: Exploration parameter (>0.0)  
- ~q_values~: Current Q-value estimates
- ~arm_counts~: Selection counts per arm
- ~total_rewards~: Cumulative rewards per arm

** Core Functions

*** run_metal_bandit_simulation!
#+BEGIN_SRC julia
run_metal_bandit_simulation!(env::MetalBernoulliEnvironment{T}, 
                            agent::MetalQLearningAgent{T};
                            batch_size::Int = 1000)
#+END_SRC

Runs the main Q-learning simulation with GPU acceleration.

*Parameters*:
- ~env~: Environment to simulate
- ~agent~: Q-learning agent
- ~batch_size~: Memory-efficient batch processing size

*** gpu_mle_parameter_estimation
#+BEGIN_SRC julia
gpu_mle_parameter_estimation(env::MetalBernoulliEnvironment{T}, 
                            agent::MetalQLearningAgent{T};
                            use_batch_processing::Bool = true,
                            batch_size::Int = 1000)
#+END_SRC

Performs GPU-accelerated MLE parameter estimation.

*Returns*: ~Array{T, 2}~ - Estimated parameters (n_arms Ã— n_agents)

*** analyze_parameter_recovery
#+BEGIN_SRC julia
analyze_parameter_recovery(true_params::Array{T1, 2}, 
                          estimated_params::Array{T2, 2})
#+END_SRC

Computes comprehensive recovery metrics.

*Returns*: ~(recovery_metrics, absolute_errors, relative_errors)~

*** plot_parameter_recovery
#+BEGIN_SRC julia
plot_parameter_recovery(true_params::Array{T1, 2}, 
                       estimated_params::Array{T2, 2};
                       title_prefix::String = "Parameter Recovery")
#+END_SRC

Creates comprehensive parameter recovery visualizations.

*Returns*: ~(recovery_plot, recovery_metrics)~

** Utility Functions

*** demonstrate_metal_bandit_simulator
#+BEGIN_SRC julia
demonstrate_metal_bandit_simulator()
#+END_SRC

Runs a complete demonstration with default parameters.

*** benchmark_metal_bandit_simulator
#+BEGIN_SRC julia
benchmark_metal_bandit_simulator(n_arms_list = [5, 10, 20], 
                                n_agents_list = [100, 500, 1000],
                                n_trials_list = [1000, 5000];
                                alpha::Float32 = 0.1f0,
                                beta::Float32 = 2.0f0)
#+END_SRC

Runs comprehensive performance benchmarks.

* Examples and Tutorials

** Tutorial 1: Basic Parameter Recovery

Goal: Understand how well the simulator recovers known parameters.

#+BEGIN_SRC julia
# Step 1: Create environment with known parameters
n_arms, n_agents = 4, 100
true_reward_probs = [0.2, 0.4, 0.6, 0.8]  # Increasing reward probabilities
true_params = repeat(true_reward_probs, 1, n_agents)

env = MetalBernoulliEnvironment(n_arms, 2000, n_agents; true_params=true_params)

# Step 2: Create agent with moderate exploration
agent = MetalQLearningAgent(n_arms, n_agents, 2000; alpha=0.1f0, beta=2.0f0)

# Step 3: Run simulation
println("Running simulation...")
run_metal_bandit_simulation!(env, agent)

# Step 4: Estimate parameters
println("Estimating parameters...")
estimated_params = gpu_mle_parameter_estimation(env, agent)

# Step 5: Analyze results
recovery_plot, metrics = plot_parameter_recovery(true_params, estimated_params)

println("Results:")
println("  True parameters: ", true_reward_probs)
println("  Estimated (mean): ", round.(mean(estimated_params, dims=2)[:], digits=3))
println("  Recovery RÂ²: ", round(metrics.r_squared, digits=4))
println("  Mean Absolute Error: ", round(metrics.mae, digits=4))

display(recovery_plot)
#+END_SRC

** Tutorial 2: Exploration vs Exploitation

Goal: Compare different exploration strategies.

#+BEGIN_SRC julia
# Test different beta values (exploration parameters)
beta_values = [0.5f0, 1.0f0, 2.0f0, 5.0f0, 10.0f0]
results = []

for beta in beta_values
    println("Testing beta = $beta...")
    
    # Create identical environments
    env = MetalBernoulliEnvironment(6, 1500, 150)
    true_params = Array(env.true_params)
    
    # Agent with different exploration
    agent = MetalQLearningAgent(6, 150, 1500; alpha=0.1f0, beta=beta)
    
    # Run simulation
    run_metal_bandit_simulation!(env, agent)
    estimated_params = gpu_mle_parameter_estimation(env, agent)
    
    # Analyze recovery
    metrics, _, _ = analyze_parameter_recovery(true_params, estimated_params)
    
    # Check final Q-values (exploration indicator)
    q_values = Array(agent.q_values)
    q_value_spread = std(q_values, dims=1) |> mean
    
    push!(results, (
        beta = beta,
        recovery_r2 = metrics.r_squared,
        mae = metrics.mae,
        q_spread = q_value_spread
    ))
end

# Display results
println("\nExploration Analysis:")
println("Beta\tRÂ²\tMAE\tQ-Spread")
for result in results
    @printf "%.1f\t%.3f\t%.3f\t%.3f\n" result.beta result.recovery_r2 result.mae result.q_spread
end

# Plot exploration vs performance
using Plots
plot([r.beta for r in results], [r.recovery_r2 for r in results],
     marker=:circle, xlabel="Exploration Parameter (Î²)", ylabel="Recovery RÂ²",
     title="Exploration vs Parameter Recovery")
#+END_SRC

** Tutorial 3: Scaling Analysis

Goal: Understand how performance scales with problem size.

#+BEGIN_SRC julia
# Define scaling dimensions
agent_counts = [50, 100, 200, 500, 1000]
scaling_results = []

for n_agents in agent_counts
    println("Testing with $n_agents agents...")
    
    # Fixed problem structure, varying agents
    n_arms, n_trials = 8, 1000
    
    env = MetalBernoulliEnvironment(n_arms, n_trials, n_agents)
    agent = MetalQLearningAgent(n_arms, n_agents, n_trials)
    
    # Measure performance
    sim_time = @elapsed run_metal_bandit_simulation!(env, agent)
    mle_time = @elapsed estimated_params = gpu_mle_parameter_estimation(env, agent)
    
    total_ops = n_arms * n_agents * n_trials
    throughput = total_ops / (sim_time + mle_time)
    
    # Check accuracy
    true_params = Array(env.true_params)
    metrics, _, _ = analyze_parameter_recovery(true_params, estimated_params)
    
    push!(scaling_results, (
        n_agents = n_agents,
        sim_time = sim_time,
        mle_time = mle_time,
        total_time = sim_time + mle_time,
        throughput = throughput,
        accuracy = metrics.r_squared
    ))
end

# Analyze scaling
println("\nScaling Analysis:")
println("Agents\tSim(s)\tMLE(s)\tTotal(s)\tThroughput\tAccuracy")
for result in scaling_results
    @printf "%d\t%.2f\t%.2f\t%.2f\t%.0f\t\t%.3f\n" result.n_agents result.sim_time result.mle_time result.total_time result.throughput result.accuracy
end

# Plot scaling characteristics
p1 = plot([r.n_agents for r in scaling_results], [r.throughput for r in scaling_results],
          marker=:circle, xlabel="Number of Agents", ylabel="Throughput (ops/s)",
          title="Throughput Scaling")

p2 = plot([r.n_agents for r in scaling_results], [r.total_time for r in scaling_results],
          marker=:square, xlabel="Number of Agents", ylabel="Total Time (s)",
          title="Time Scaling")

plot(p1, p2, layout=(1,2), size=(800,300))
#+END_SRC

* Best Practices

** Performance Best Practices

*** Problem Size Selection
1. *Start Small*: Begin with 10-100 agents for development
2. *Scale Gradually*: Increase problem size to find optimal performance point
3. *GPU Sweet Spot*: 500-2000 agents typically maximize GPU utilization
4. *Memory Awareness*: Monitor memory usage as you scale

*** Data Type Optimization
#+BEGIN_SRC julia
# Good: Use Float32 for GPU
true_params = rand(Float32, n_arms, n_agents)

# Avoid: Float64 unnecessarily increases memory usage
# true_params = rand(Float64, n_arms, n_agents)  # Don't do this
#+END_SRC

*** Batch Size Selection
#+BEGIN_SRC julia
# For memory-constrained systems (8GB)
run_metal_bandit_simulation!(env, agent; batch_size=200)

# For high-memory systems (32GB+)
run_metal_bandit_simulation!(env, agent; batch_size=2000)
#+END_SRC

** Algorithm Best Practices

*** Learning Rate Selection
- *Conservative*: Î± = 0.01-0.05 for stable learning
- *Standard*: Î± = 0.1 for balanced performance
- *Aggressive*: Î± = 0.2-0.5 for rapid adaptation

*** Exploration Parameter Selection  
- *Low Exploration*: Î² = 0.5-1.0 for exploitation focus
- *Balanced*: Î² = 2.0-5.0 for exploration-exploitation balance
- *High Exploration*: Î² = 10.0+ for thorough exploration

*** Problem Design
#+BEGIN_SRC julia
# Good: Diverse reward probabilities for interesting problems
true_params = [0.1, 0.3, 0.5, 0.7, 0.9]  # Clear differences

# Avoid: Too similar probabilities make recovery difficult
# true_params = [0.45, 0.47, 0.49, 0.51, 0.53]  # Hard to distinguish
#+END_SRC

** Code Organization Best Practices

*** Modular Analysis
#+BEGIN_SRC julia
function run_analysis(config)
    env = MetalBernoulliEnvironment(config.n_arms, config.n_trials, config.n_agents)
    agent = MetalQLearningAgent(config.n_arms, config.n_agents, config.n_trials;
                               alpha=config.alpha, beta=config.beta)
    
    run_metal_bandit_simulation!(env, agent)
    estimated_params = gpu_mle_parameter_estimation(env, agent)
    
    true_params = Array(env.true_params)
    return analyze_parameter_recovery(true_params, estimated_params)
end

# Use for multiple configurations
configs = [
    (n_arms=5, n_trials=1000, n_agents=100, alpha=0.1f0, beta=2.0f0),
    (n_arms=5, n_trials=1000, n_agents=100, alpha=0.05f0, beta=5.0f0)
]

results = [run_analysis(config) for config in configs]
#+END_SRC

*** Error Handling
#+BEGIN_SRC julia
function safe_simulation(n_arms, n_trials, n_agents)
    try
        env = MetalBernoulliEnvironment(n_arms, n_trials, n_agents)
        agent = MetalQLearningAgent(n_arms, n_agents, n_trials)
        
        run_metal_bandit_simulation!(env, agent)
        return gpu_mle_parameter_estimation(env, agent)
    catch e
        println("Simulation failed: $e")
        println("Falling back to smaller problem size...")
        
        # Retry with smaller problem
        return safe_simulation(max(2, n_armsÃ·2), max(10, n_trialsÃ·2), max(5, n_agentsÃ·2))
    end
end
#+END_SRC

** Research Best Practices

*** Reproducibility
#+BEGIN_SRC julia
# Set random seed for reproducible results
using Random
Random.seed!(42)

# Document configuration
config = (
    n_arms = 8,
    n_trials = 2000, 
    n_agents = 500,
    alpha = 0.1f0,
    beta = 3.0f0,
    seed = 42
)

# Save results with configuration
results = run_analysis(config)
save("results_seed_$(config.seed).jld2", "config", config, "results", results)
#+END_SRC

*** Statistical Validation
#+BEGIN_SRC julia
# Run multiple replications for statistical analysis
n_replications = 10
replication_results = []

for rep in 1:n_replications
    Random.seed!(rep)  # Different seed per replication
    
    env = MetalBernoulliEnvironment(8, 2000, 200)
    agent = MetalQLearningAgent(8, 200, 2000; alpha=0.1f0, beta=2.0f0)
    
    run_metal_bandit_simulation!(env, agent)
    estimated_params = gpu_mle_parameter_estimation(env, agent)
    
    true_params = Array(env.true_params) 
    metrics, _, _ = analyze_parameter_recovery(true_params, estimated_params)
    
    push!(replication_results, metrics.r_squared)
end

# Statistical summary
println("Recovery RÂ² across replications:")
println("  Mean: ", round(mean(replication_results), digits=4))
println("  Std:  ", round(std(replication_results), digits=4))
println("  95% CI: [", round(quantile(replication_results, 0.025), digits=4),
        ", ", round(quantile(replication_results, 0.975), digits=4), "]")
#+END_SRC

This manual provides comprehensive guidance for using MetalBandit effectively. For additional support, refer to the test suite examples and the development log for implementation details.