using Metal
using Statistics
using Random
using Distributions
using Optim
using CSV
using DataFrames
using LinearAlgebra
using StatsBase
using BenchmarkTools

# Import CairoMakie explicitly to avoid plotting conflicts
import CairoMakie
using CairoMakie: Figure, Axis, scatter!, lines!, hist!, hlines!, heatmap!, text!, save, Colorbar, Label, axislegend, barplot!

# Include the comparison framework
include("gpu_vs_cpu_comparison.jl")

"""
Large-scale GPU vs CPU comparison experiment
"""
function run_large_scale_comparison(;
    n_subjects::Int = 2000,
    n_arms::Int = 8,
    n_trials::Int = 500,
    n_threads::Int = 8,
    seed::Int = 42
)
    
    println("ğŸš€ LARGE-SCALE GPU vs CPU Qå­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å›å¾©æ¯”è¼ƒå®Ÿé¨“")
    println("=" ^ 80)
    println("ã‚¹ã‚±ãƒ¼ãƒ«: $(n_subjects) subjects Ã— $(n_arms) arms Ã— $(n_trials) trials")
    println("ç·æ±ºå®šæ•°: $(n_subjects * n_trials) decisions")
    println("ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: $(n_threads)")
    println("ã‚·ãƒ¼ãƒ‰: $(seed)")
    println()
    
    # Verify threading
    println("åˆ©ç”¨å¯èƒ½ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: $(Threads.nthreads())")
    if Threads.nthreads() < n_threads
        @warn "æœŸå¾…ã‚¹ãƒ¬ãƒƒãƒ‰æ•° $(n_threads) ã‚ˆã‚Šå°‘ãªã„ $(Threads.nthreads()) ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œä¸­"
    end
    println()
    
    # Memory usage estimation
    memory_per_subject_mb = (n_trials * (4 + 8) + n_arms * 8 + 100) / 1024 / 1024
    total_memory_mb = memory_per_subject_mb * n_subjects
    println("æ¨å®šãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: $(round(total_memory_mb, digits=1)) MB")
    println()
    
    # Run the comparison with large scale parameters
    comparison, timing_results = run_fair_gpu_vs_cpu_comparison(
        n_subjects, n_arms, n_trials; seed=seed
    )
    
    return comparison, timing_results
end

"""
Create large-scale performance analysis visualization
"""
function create_large_scale_visualization(comparison, timing_results, small_scale_results=nothing)
    println("ğŸ¨ å¤§è¦æ¨¡å®Ÿé¨“å¯è¦–åŒ–ä½œæˆä¸­...")
    
    fig = Figure(size=(1800, 1400), fontsize=14)
    
    # 1. Performance comparison bar chart
    ax1 = Axis(fig[1, 1],
               xlabel="Method", ylabel="Time (seconds)",
               title="Large-Scale Performance Comparison")
    
    methods = ["GPU", "CPU (8 threads)", "CPU (1 thread)"]
    times = [timing_results.gpu_time, timing_results.cpu_threaded_time, timing_results.cpu_sequential_time]
    colors = [:blue, :red, :orange]
    
    barplot!(ax1, 1:3, times, color=colors, alpha=0.7)
    ax1.xticks = (1:3, methods)
    
    # Add timing labels
    for (i, time) in enumerate(times)
        text!(ax1, i, time + maximum(times)*0.02, 
              text="$(round(time, digits=1))s", 
              align=(:center, :bottom), fontsize=12)
    end
    
    # 2. Speedup analysis
    ax2 = Axis(fig[1, 2],
               xlabel="Comparison", ylabel="Speedup Factor",
               title="GPU Performance Analysis")
    
    speedup_labels = ["GPU vs\nCPU (8 threads)", "GPU vs\nCPU (1 thread)"]
    speedup_values = [timing_results.cpu_threaded_time / timing_results.gpu_time,
                     timing_results.cpu_sequential_time / timing_results.gpu_time]
    speedup_colors = [val > 1.0 ? :green : :red for val in speedup_values]
    
    barplot!(ax2, 1:2, speedup_values, color=speedup_colors, alpha=0.7)
    ax2.xticks = (1:2, speedup_labels)
    
    # Add speedup labels
    for (i, speedup) in enumerate(speedup_values)
        text!(ax2, i, speedup + maximum(speedup_values)*0.02,
              text="$(round(speedup, digits=2))x",
              align=(:center, :bottom), fontsize=12)
    end
    
    # Reference line at 1x
    hlines!(ax2, [1.0], color=:black, linestyle=:dash, alpha=0.5)
    
    # 3. Scale comparison (if small scale results provided)
    if small_scale_results !== nothing
        ax3 = Axis(fig[2, 1],
                   xlabel="Scale", ylabel="Time (seconds)",
                   title="Scaling Performance Analysis")
        
        # This would need small scale timing data
        # For now, create placeholder
        scales = ["Small\n(200Ã—4Ã—200)", "Large\n(2000Ã—8Ã—500)"]
        ax3.xticks = (1:2, scales)
        text!(ax3, 1, 0.5, text="Small scale\nresults needed", align=(:center, :center))
    end
    
    # 4. Parameter recovery quality
    ax4 = Axis(fig[2, 2],
               xlabel="Parameter", ylabel="Correlation",
               title="Parameter Recovery Quality")
    
    success_idx_gpu = comparison.gpu_estimation_success
    success_idx_cpu = comparison.cpu_estimation_success
    
    if sum(success_idx_gpu) > 0 && sum(success_idx_cpu) > 0
        gpu_Î±_corr = cor(comparison.true_alpha[success_idx_gpu], 
                         comparison.gpu_estimated_alpha[success_idx_gpu])
        gpu_Î²_corr = cor(comparison.true_beta[success_idx_gpu], 
                         comparison.gpu_estimated_beta[success_idx_gpu])
        cpu_Î±_corr = cor(comparison.true_alpha[success_idx_cpu], 
                         comparison.cpu_estimated_alpha[success_idx_cpu])
        cpu_Î²_corr = cor(comparison.true_beta[success_idx_cpu], 
                         comparison.cpu_estimated_beta[success_idx_cpu])
        
        barplot!(ax4, [1, 1.3], [gpu_Î±_corr, cpu_Î±_corr], 
                color=[:blue, :red], alpha=0.7, width=0.25)
        barplot!(ax4, [2, 2.3], [gpu_Î²_corr, cpu_Î²_corr], 
                color=[:blue, :red], alpha=0.7, width=0.25)
        
        ax4.xticks = ([1.15, 2.15], ["Learning Rate Î±", "Inverse Temp Î²"])
        
        # Legend
        scatter!(ax4, [0], [0], color=:blue, label="GPU", markersize=0)
        scatter!(ax4, [0], [0], color=:red, label="CPU", markersize=0)
        axislegend(ax4)
    end
    
    # 5. Success rate comparison
    ax5 = Axis(fig[3, 1],
               xlabel="Method", ylabel="Success Rate (%)",
               title="Parameter Estimation Success Rate")
    
    gpu_success_rate = mean(comparison.gpu_estimation_success) * 100
    cpu_success_rate = mean(comparison.cpu_estimation_success) * 100
    
    success_methods = ["GPU", "CPU"]
    success_rates = [gpu_success_rate, cpu_success_rate]
    
    barplot!(ax5, 1:2, success_rates, color=[:blue, :red], alpha=0.7)
    ax5.xticks = (1:2, success_methods)
    
    for (i, rate) in enumerate(success_rates)
        text!(ax5, i, rate + 2, text="$(round(rate, digits=1))%", 
              align=(:center, :bottom), fontsize=12)
    end
    
    # 6. Performance summary text
    Label(fig[3, 2], 
          "Large-Scale Performance Summary\\n\\n" *
          "Dataset Size:\\n" *
          "Subjects: $(comparison.n_subjects)\\n" *
          "Arms: $(comparison.n_arms)\\n" *
          "Trials: $(comparison.n_trials)\\n" *
          "Total Decisions: $(comparison.n_subjects * comparison.n_trials)\\n\\n" *
          "Execution Time:\\n" *
          "GPU: $(round(timing_results.gpu_time, digits=1))s\\n" *
          "CPU (8 threads): $(round(timing_results.cpu_threaded_time, digits=1))s\\n" *
          "CPU (1 thread): $(round(timing_results.cpu_sequential_time, digits=1))s\\n\\n" *
          "GPU Speedup:\\n" *
          "vs CPU (8 threads): $(round(timing_results.cpu_threaded_time/timing_results.gpu_time, digits=2))x\\n" *
          "vs CPU (1 thread): $(round(timing_results.cpu_sequential_time/timing_results.gpu_time, digits=2))x\\n\\n" *
          "Success Rate:\\n" *
          "GPU: $(round(mean(comparison.gpu_estimation_success)*100, digits=1))%\\n" *
          "CPU: $(round(mean(comparison.cpu_estimation_success)*100, digits=1))%",
          fontsize=11, halign=:left, valign=:top)
    
    return fig
end

"""
Save large-scale results with detailed analysis
"""
function save_large_scale_results(comparison, timing_results, 
                                filename_prefix::String="large_scale_gpu_vs_cpu")
    
    # Save detailed comparison results
    results_filename = "$(filename_prefix)_results.csv"
    timing_filename = "$(filename_prefix)_timing.csv"
    
    # Detailed results
    df = DataFrame(
        subject_id = 1:comparison.n_subjects,
        true_alpha = comparison.true_alpha,
        true_beta = comparison.true_beta,
        gpu_estimated_alpha = comparison.gpu_estimated_alpha,
        gpu_estimated_beta = comparison.gpu_estimated_beta,
        gpu_estimation_success = comparison.gpu_estimation_success,
        cpu_estimated_alpha = comparison.cpu_estimated_alpha,
        cpu_estimated_beta = comparison.cpu_estimated_beta,
        cpu_estimation_success = comparison.cpu_estimation_success,
        gpu_alpha_error = comparison.gpu_estimated_alpha - comparison.true_alpha,
        gpu_beta_error = comparison.gpu_estimated_beta - comparison.true_beta,
        cpu_alpha_error = comparison.cpu_estimated_alpha - comparison.true_alpha,
        cpu_beta_error = comparison.cpu_estimated_beta - comparison.true_beta
    )
    
    CSV.write(results_filename, df)
    println("ğŸ“ å¤§è¦æ¨¡æ¯”è¼ƒçµæœã‚’ $(results_filename) ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    # Timing analysis
    timing_df = DataFrame(
        method = ["GPU", "CPU_8_Threads", "CPU_1_Thread"],
        time_seconds = [timing_results.gpu_time, timing_results.cpu_threaded_time, timing_results.cpu_sequential_time],
        speedup_vs_gpu = [1.0, 
                         timing_results.gpu_time/timing_results.cpu_threaded_time, 
                         timing_results.gpu_time/timing_results.cpu_sequential_time],
        dataset_scale = ["$(comparison.n_subjects)Ã—$(comparison.n_arms)Ã—$(comparison.n_trials)" for _ in 1:3],
        total_decisions = [comparison.n_subjects * comparison.n_trials for _ in 1:3]
    )
    
    CSV.write(timing_filename, timing_df)
    println("ğŸ“ å¤§è¦æ¨¡ã‚¿ã‚¤ãƒŸãƒ³ã‚°çµæœã‚’ $(timing_filename) ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    return df, timing_df
end

"""
Main large-scale experiment execution
"""
function main_large_scale_experiment()
    println("ğŸ”¥ LARGE-SCALE GPU vs CPU Qå­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å›å¾©å®Ÿé¨“é–‹å§‹")
    println("=" ^ 90)
    
    # Check system resources
    println("ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±:")
    println("  åˆ©ç”¨å¯èƒ½ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: $(Threads.nthreads())")
    try
        # Try to get system memory info
        mem_info = read(`sysctl hw.memsize`, String)
        mem_gb = parse(Int, split(mem_info)[2]) / 1024^3
        println("  ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª: $(round(mem_gb, digits=1)) GB")
    catch
        println("  ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª: æƒ…å ±å–å¾—ä¸å¯")
    end
    println()
    
    # Run large-scale comparison
    comparison, timing_results = run_large_scale_comparison(
        n_subjects=2000,
        n_arms=8, 
        n_trials=500,
        n_threads=8,
        seed=42
    )
    
    # Create visualization
    fig = create_large_scale_visualization(comparison, timing_results)
    
    # Save results
    df, timing_df = save_large_scale_results(comparison, timing_results)
    
    # Save visualization
    save("large_scale_gpu_vs_cpu_visualization.png", fig, size=(1800, 1400))
    println("ğŸ¨ å¤§è¦æ¨¡æ¯”è¼ƒå¯è¦–åŒ–ã‚’ large_scale_gpu_vs_cpu_visualization.png ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    # Performance analysis
    println("\\n" * "=" * 80)
    println("ğŸ† LARGE-SCALE PERFORMANCE ANALYSIS")
    println("=" * 80)
    
    gpu_vs_cpu_8_speedup = timing_results.cpu_threaded_time / timing_results.gpu_time
    gpu_vs_cpu_1_speedup = timing_results.cpu_sequential_time / timing_results.gpu_time
    
    println("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¦æ¨¡:")
    println("  è¢«é¨“è€…æ•°: $(comparison.n_subjects)")
    println("  ã‚¢ãƒ¼ãƒ æ•°: $(comparison.n_arms)")  
    println("  è©¦è¡Œæ•°: $(comparison.n_trials)")
    println("  ç·æ±ºå®šæ•°: $(comparison.n_subjects * comparison.n_trials)")
    println()
    
    println("å®Ÿè¡Œæ™‚é–“:")
    println("  GPU: $(round(timing_results.gpu_time, digits=2))s")
    println("  CPU (8ã‚¹ãƒ¬ãƒƒãƒ‰): $(round(timing_results.cpu_threaded_time, digits=2))s")
    println("  CPU (1ã‚¹ãƒ¬ãƒƒãƒ‰): $(round(timing_results.cpu_sequential_time, digits=2))s")
    println()
    
    println("GPUæ€§èƒ½åˆ†æ:")
    if gpu_vs_cpu_8_speedup > 1.0
        println("  ğŸš€ GPU ã¯ 8ã‚¹ãƒ¬ãƒƒãƒ‰CPU ã‚ˆã‚Š $(round(gpu_vs_cpu_8_speedup, digits=2))x é«˜é€Ÿ")
    else
        println("  âš¡ 8ã‚¹ãƒ¬ãƒƒãƒ‰CPU ã¯ GPU ã‚ˆã‚Š $(round(1/gpu_vs_cpu_8_speedup, digits=2))x é«˜é€Ÿ")
    end
    
    if gpu_vs_cpu_1_speedup > 1.0
        println("  ğŸš€ GPU ã¯ 1ã‚¹ãƒ¬ãƒƒãƒ‰CPU ã‚ˆã‚Š $(round(gpu_vs_cpu_1_speedup, digits=2))x é«˜é€Ÿ")
    else
        println("  âš¡ 1ã‚¹ãƒ¬ãƒƒãƒ‰CPU ã¯ GPU ã‚ˆã‚Š $(round(1/gpu_vs_cpu_1_speedup, digits=2))x é«˜é€Ÿ")
    end
    println()
    
    println("æ¨å®šç²¾åº¦:")
    println("  GPUæˆåŠŸç‡: $(round(mean(comparison.gpu_estimation_success)*100, digits=1))%")
    println("  CPUæˆåŠŸç‡: $(round(mean(comparison.cpu_estimation_success)*100, digits=1))%")
    
    println("\\nâœ… å¤§è¦æ¨¡GPU vs CPUæ¯”è¼ƒå®Ÿé¨“å®Œäº†ï¼")
    
    return comparison, timing_results, fig, df, timing_df
end

# Export functions
export run_large_scale_comparison, create_large_scale_visualization,
       save_large_scale_results, main_large_scale_experiment