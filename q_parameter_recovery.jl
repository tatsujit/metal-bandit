using Metal
using Statistics
using Random
using Distributions
using Optim
using CSV
using DataFrames
using LinearAlgebra
using StatsBase

# Import CairoMakie explicitly to avoid plotting conflicts
import CairoMakie
using CairoMakie: Figure, Axis, scatter!, lines!, hist!, hlines!, heatmap!, text!, save, Colorbar, Label, axislegend

# Include the main simulator
include("metal_bandit_simulator.jl")

"""
Qå­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å›å¾©å®Ÿé¨“ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
"""
struct ParameterRecoveryExperiment
    n_subjects::Int                    # è¢«é¨“è€…æ•°ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ„ã¿åˆã‚ã›æ•°ï¼‰
    n_arms::Int                       # ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã‚¢ãƒ¼ãƒ æ•°
    n_trials::Int                     # è©¦è¡Œæ•°
    true_alpha::Vector{Float64}       # çœŸã®å­¦ç¿’ç‡
    true_beta::Vector{Float64}        # çœŸã®é€†æ¸©åº¦
    estimated_alpha::Vector{Float64}  # æ¨å®šå­¦ç¿’ç‡
    estimated_beta::Vector{Float64}   # æ¨å®šé€†æ¸©åº¦
    actions::Matrix{Int}              # è¡Œå‹•ãƒ‡ãƒ¼ã‚¿ (n_trials Ã— n_subjects)
    rewards::Matrix{Float64}          # å ±é…¬ãƒ‡ãƒ¼ã‚¿ (n_trials Ã— n_subjects)
    true_reward_probs::Matrix{Float64} # çœŸã®å ±é…¬ç¢ºç‡ (n_arms Ã— n_subjects)
    log_likelihoods::Vector{Float64}  # å¯¾æ•°å°¤åº¦
    estimation_success::Vector{Bool}  # æ¨å®šæˆåŠŸãƒ•ãƒ©ã‚°
end

"""
å˜ä¸€è¢«é¨“è€…ã®Qå­¦ç¿’è¡Œå‹•ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
"""
function generate_q_learning_behavior(true_alpha::Float64, true_beta::Float64, 
                                     reward_probs::Vector{Float64}, n_trials::Int)
    n_arms = length(reward_probs)
    actions = zeros(Int, n_trials)
    rewards = zeros(Float64, n_trials)
    q_values = fill(0.5, n_arms)  # Qå€¤åˆæœŸåŒ–
    
    for trial in 1:n_trials
        # Softmaxè¡Œå‹•é¸æŠ
        action_probs = softmax(true_beta .* q_values)
        actions[trial] = StatsBase.sample(1:n_arms, Weights(action_probs))
        
        # å ±é…¬ç”Ÿæˆ
        rewards[trial] = rand() < reward_probs[actions[trial]] ? 1.0 : 0.0
        
        # Qå€¤æ›´æ–°
        prediction_error = rewards[trial] - q_values[actions[trial]]
        q_values[actions[trial]] += true_alpha * prediction_error
    end
    
    return actions, rewards
end

"""
Softmaxé–¢æ•°ï¼ˆæ•°å€¤å®‰å®šç‰ˆï¼‰
"""
function softmax(x::Vector{Float64})
    max_x = maximum(x)
    exp_x = exp.(x .- max_x)
    return exp_x ./ sum(exp_x)
end


"""
Qå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è² å¯¾æ•°å°¤åº¦è¨ˆç®—
"""
function negative_log_likelihood(params::Vector{Float64}, actions::Vector{Int}, 
                                rewards::Vector{Float64}, n_arms::Int)
    alpha, beta = params
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¢ƒç•Œãƒã‚§ãƒƒã‚¯
    if alpha <= 0 || alpha >= 1 || beta <= 0 || beta >= 20
        return Inf
    end
    
    n_trials = length(actions)
    q_values = fill(0.5, n_arms)
    nll = 0.0
    
    for trial in 1:n_trials
        # ç¾åœ¨ã®Qå€¤ã«åŸºã¥ãè¡Œå‹•ç¢ºç‡
        action_probs = softmax(beta .* q_values)
        
        # è² å¯¾æ•°å°¤åº¦ã«è¿½åŠ 
        prob = action_probs[actions[trial]]
        nll -= log(max(prob, 1e-10))  # æ•°å€¤å®‰å®šåŒ–
        
        # Qå€¤æ›´æ–°
        prediction_error = rewards[trial] - q_values[actions[trial]]
        q_values[actions[trial]] += alpha * prediction_error
    end
    
    return nll
end

"""
å˜ä¸€è¢«é¨“è€…ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®š
"""
function estimate_q_parameters(actions::Vector{Int}, rewards::Vector{Float64}, n_arms::Int;
                              n_restarts::Int = 10)
    best_result = nothing
    best_nll = Inf
    
    for restart in 1:n_restarts
        # ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸå€¤
        initial_alpha = rand() * 0.8 + 0.1  # [0.1, 0.9]
        initial_beta = rand() * 8 + 1       # [1, 9]
        
        try
            result = optimize(
                params -> negative_log_likelihood(params, actions, rewards, n_arms),
                [initial_alpha, initial_beta],
                BFGS(),
                Optim.Options(iterations=1000, g_tol=1e-6)
            )
            
            if Optim.converged(result) && result.minimum < best_nll
                best_nll = result.minimum
                best_result = result
            end
        catch e
            # æœ€é©åŒ–å¤±æ•—æ™‚ã¯æ¬¡ã®ãƒªã‚¹ã‚¿ãƒ¼ãƒˆã¸
            continue
        end
    end
    
    if best_result === nothing
        return [NaN, NaN], Inf, false
    end
    
    estimated_params = Optim.minimizer(best_result)
    return estimated_params, best_nll, true
end

"""
ãƒ¡ã‚¤ãƒ³å®Ÿé¨“å®Ÿè¡Œé–¢æ•°
"""
function run_parameter_recovery_experiment(n_subjects::Int = 1000, n_arms::Int = 4, 
                                         n_trials::Int = 200; seed::Int = 42)
    Random.seed!(seed)
    
    println("ğŸ§  Qå­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å›å¾©å®Ÿé¨“é–‹å§‹")
    println("è¢«é¨“è€…æ•°: $n_subjects, ã‚¢ãƒ¼ãƒ æ•°: $n_arms, è©¦è¡Œæ•°: $n_trials")
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    true_alpha = rand(n_subjects)                    # [0, 1]
    true_beta = rand(n_subjects) * 10               # [0, 10]
    
    # çµæœæ ¼ç´ç”¨é…åˆ—
    estimated_alpha = zeros(n_subjects)
    estimated_beta = zeros(n_subjects)
    actions = zeros(Int, n_trials, n_subjects)
    rewards = zeros(Float64, n_trials, n_subjects)
    true_reward_probs = rand(n_arms, n_subjects) * 0.6 .+ 0.2  # [0.2, 0.8]
    log_likelihoods = zeros(n_subjects)
    estimation_success = fill(false, n_subjects)
    
    # å„è¢«é¨“è€…ã«ã¤ã„ã¦å®Ÿé¨“å®Ÿè¡Œ
    println("ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®šå®Ÿè¡Œä¸­...")
    progress_interval = max(1, n_subjects Ã· 20)
    
    Threads.@threads for subject in 1:n_subjects
        if subject % progress_interval == 0
            println("  é€²æ—: $subject / $n_subjects ($(round(subject/n_subjects*100, digits=1))%)")
        end
        
        # è¡Œå‹•ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        subject_actions, subject_rewards = generate_q_learning_behavior(
            true_alpha[subject], 
            true_beta[subject],
            true_reward_probs[:, subject],
            n_trials
        )
        
        actions[:, subject] = subject_actions
        rewards[:, subject] = subject_rewards
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®š
        estimated_params, nll, success = estimate_q_parameters(
            subject_actions, subject_rewards, n_arms
        )
        
        if success
            estimated_alpha[subject] = estimated_params[1]
            estimated_beta[subject] = estimated_params[2]
            log_likelihoods[subject] = -nll
            estimation_success[subject] = true
        else
            estimated_alpha[subject] = NaN
            estimated_beta[subject] = NaN
            log_likelihoods[subject] = NaN
            estimation_success[subject] = false
        end
    end
    
    success_rate = mean(estimation_success)
    println("âœ… å®Ÿé¨“å®Œäº†ï¼æ¨å®šæˆåŠŸç‡: $(round(success_rate*100, digits=1))%")
    
    return ParameterRecoveryExperiment(
        n_subjects, n_arms, n_trials,
        true_alpha, true_beta,
        estimated_alpha, estimated_beta,
        actions, rewards, true_reward_probs,
        log_likelihoods, estimation_success
    )
end

"""
å®Ÿé¨“çµæœã®è©³ç´°åˆ†æ
"""
function analyze_recovery_results(experiment::ParameterRecoveryExperiment)
    success_idx = experiment.estimation_success
    
    if sum(success_idx) == 0
        println("âŒ æ¨å®šæˆåŠŸã—ãŸãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return nothing
    end
    
    # æˆåŠŸã—ãŸãƒ‡ãƒ¼ã‚¿ã®ã¿åˆ†æ
    true_Î± = experiment.true_alpha[success_idx]
    true_Î² = experiment.true_beta[success_idx]
    est_Î± = experiment.estimated_alpha[success_idx]
    est_Î² = experiment.estimated_beta[success_idx]
    
    # Î±ã®å›å¾©çµ±è¨ˆ
    Î±_correlation = cor(true_Î±, est_Î±)
    Î±_mae = mean(abs.(true_Î± - est_Î±))
    Î±_rmse = sqrt(mean((true_Î± - est_Î±).^2))
    Î±_r2 = Î±_correlation^2
    
    # Î²ã®å›å¾©çµ±è¨ˆ
    Î²_correlation = cor(true_Î², est_Î²)
    Î²_mae = mean(abs.(true_Î² - est_Î²))
    Î²_rmse = sqrt(mean((true_Î² - est_Î²).^2))
    Î²_r2 = Î²_correlation^2
    
    # ãƒã‚¤ã‚¢ã‚¹åˆ†æ
    Î±_bias = mean(est_Î± - true_Î±)
    Î²_bias = mean(est_Î² - true_Î²)
    
    println("\nğŸ“Š ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å›å¾©åˆ†æçµæœ")
    println("=" ^ 50)
    println("æˆåŠŸç‡: $(round(mean(experiment.estimation_success)*100, digits=1))%")
    println("æˆåŠŸãƒ‡ãƒ¼ã‚¿æ•°: $(sum(success_idx)) / $(experiment.n_subjects)")
    println()
    println("ã€å­¦ç¿’ç‡ Î± ã®å›å¾©ã€‘")
    println("  ç›¸é–¢ä¿‚æ•°: $(round(Î±_correlation, digits=4))")
    println("  RÂ²: $(round(Î±_r2, digits=4))")
    println("  MAE: $(round(Î±_mae, digits=4))")
    println("  RMSE: $(round(Î±_rmse, digits=4))")
    println("  ãƒã‚¤ã‚¢ã‚¹: $(round(Î±_bias, digits=4))")
    println()
    println("ã€é€†æ¸©åº¦ Î² ã®å›å¾©ã€‘")
    println("  ç›¸é–¢ä¿‚æ•°: $(round(Î²_correlation, digits=4))")
    println("  RÂ²: $(round(Î²_r2, digits=4))")
    println("  MAE: $(round(Î²_mae, digits=4))")
    println("  RMSE: $(round(Î²_rmse, digits=4))")
    println("  ãƒã‚¤ã‚¢ã‚¹: $(round(Î²_bias, digits=4))")
    
    return (
        alpha_stats = (correlation=Î±_correlation, mae=Î±_mae, rmse=Î±_rmse, r2=Î±_r2, bias=Î±_bias),
        beta_stats = (correlation=Î²_correlation, mae=Î²_mae, rmse=Î²_rmse, r2=Î²_r2, bias=Î²_bias),
        n_success = sum(success_idx)
    )
end

"""
CairoMakieã‚’ç”¨ã„ãŸåŒ…æ‹¬çš„å¯è¦–åŒ–
"""
function create_recovery_visualization(experiment::ParameterRecoveryExperiment)
    println("ğŸ¨ å¯è¦–åŒ–ä½œæˆä¸­...")
    
    success_idx = experiment.estimation_success
    failed_idx = .!success_idx
    
    # æˆåŠŸãƒ»å¤±æ•—ãƒ‡ãƒ¼ã‚¿åˆ†é›¢
    true_Î±_success = experiment.true_alpha[success_idx]
    true_Î²_success = experiment.true_beta[success_idx]
    est_Î±_success = experiment.estimated_alpha[success_idx]
    est_Î²_success = experiment.estimated_beta[success_idx]
    
    true_Î±_failed = experiment.true_alpha[failed_idx]
    true_Î²_failed = experiment.true_beta[failed_idx]
    
    # å›³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    fig = Figure(size=(1400, 1000), fontsize=12)
    
    # 1. Parameter recovery scatter plots
    ax1 = Axis(fig[1, 1], 
               xlabel="True Learning Rate Î±", ylabel="Estimated Learning Rate Î±",
               title="Learning Rate Î± Recovery")
    
    if sum(success_idx) > 0
        scatter!(ax1, true_Î±_success, est_Î±_success, 
                color=:blue, alpha=0.6, markersize=8)
        
        # Perfect recovery line (y=x)
        lines!(ax1, [0, 1], [0, 1], color=:red, linestyle=:dash, linewidth=2)
        
        # Regression line
        if length(true_Î±_success) > 1
            Î±_fit = hcat(ones(length(true_Î±_success)), true_Î±_success) \ est_Î±_success
            x_line = range(minimum(true_Î±_success), maximum(true_Î±_success), length=100)
            y_line = Î±_fit[1] .+ Î±_fit[2] .* x_line
            lines!(ax1, x_line, y_line, color=:green, linewidth=2)
        end
    end
    
    ax2 = Axis(fig[1, 2],
               xlabel="True Inverse Temperature Î²", ylabel="Estimated Inverse Temperature Î²", 
               title="Inverse Temperature Î² Recovery")
    
    if sum(success_idx) > 0
        scatter!(ax2, true_Î²_success, est_Î²_success,
                color=:orange, alpha=0.6, markersize=8)
        
        # ç†æƒ³çš„ãªå›å¾©ç·š
        max_Î² = max(maximum(true_Î²_success), maximum(est_Î²_success))
        lines!(ax2, [0, max_Î²], [0, max_Î²], color=:red, linestyle=:dash, linewidth=2)
        
        # å›å¸°ç·š
        if length(true_Î²_success) > 1
            Î²_fit = hcat(ones(length(true_Î²_success)), true_Î²_success) \ est_Î²_success
            x_line = range(minimum(true_Î²_success), maximum(true_Î²_success), length=100)
            y_line = Î²_fit[1] .+ Î²_fit[2] .* x_line
            lines!(ax2, x_line, y_line, color=:green, linewidth=2)
        end
    end
    
    # 2. Parameter distributions
    ax3 = Axis(fig[2, 1], xlabel="Learning Rate Î±", ylabel="Density", title="True Î± vs Estimated Î± Distribution")
    
    if sum(success_idx) > 0
        hist!(ax3, experiment.true_alpha, bins=30, color=(:blue, 0.5), 
              label="True", normalization=:pdf)
        hist!(ax3, est_Î±_success, bins=30, color=(:red, 0.5),
              label="Estimated", normalization=:pdf)
        axislegend(ax3)
    end
    
    ax4 = Axis(fig[2, 2], xlabel="Inverse Temperature Î²", ylabel="Density", title="True Î² vs Estimated Î² Distribution")
    
    if sum(success_idx) > 0
        hist!(ax4, experiment.true_beta, bins=30, color=(:blue, 0.5),
              label="True", normalization=:pdf)
        hist!(ax4, est_Î²_success, bins=30, color=(:red, 0.5),
              label="Estimated", normalization=:pdf)
        axislegend(ax4)
    end
    
    # 3. Error analysis
    ax5 = Axis(fig[3, 1], xlabel="True Learning Rate Î±", ylabel="Estimation Error (Est - True)",
               title="Î± Estimation Error")
    
    if sum(success_idx) > 0
        Î±_errors = est_Î±_success - true_Î±_success
        scatter!(ax5, true_Î±_success, Î±_errors, color=:purple, alpha=0.6, markersize=6)
        hlines!(ax5, [0], color=:black, linestyle=:dash)
    end
    
    ax6 = Axis(fig[3, 2], xlabel="True Inverse Temperature Î²", ylabel="Estimation Error (Est - True)",
               title="Î² Estimation Error")
    
    if sum(success_idx) > 0
        Î²_errors = est_Î²_success - true_Î²_success
        scatter!(ax6, true_Î²_success, Î²_errors, color=:brown, alpha=0.6, markersize=6)
        hlines!(ax6, [0], color=:black, linestyle=:dash)
    end
    
    # 4. Success/failure distribution
    ax7 = Axis(fig[4, 1], xlabel="True Learning Rate Î±", ylabel="True Inverse Temperature Î²",
               title="Estimation Success/Failure Distribution")
    
    if sum(success_idx) > 0
        scatter!(ax7, true_Î±_success, true_Î²_success, 
                color=:green, alpha=0.7, markersize=8, label="Success")
    end
    
    if sum(failed_idx) > 0
        scatter!(ax7, true_Î±_failed, true_Î²_failed,
                color=:red, alpha=0.7, markersize=8, label="Failure")
    end
    
    if sum(success_idx) > 0 || sum(failed_idx) > 0
        axislegend(ax7)
    end
    
    # 5. Correlation matrix heatmap
    ax8 = Axis(fig[4, 2], title="Parameter Correlation")
    
    if sum(success_idx) > 0
        corr_data = [true_Î±_success true_Î²_success est_Î±_success est_Î²_success]
        corr_matrix = cor(corr_data)
        
        hm = heatmap!(ax8, corr_matrix, colormap=:RdBu, colorrange=(-1, 1))
        
        # Labels
        ax8.xticks = (1:4, ["True Î±", "True Î²", "Est Î±", "Est Î²"])
        ax8.yticks = (1:4, ["True Î±", "True Î²", "Est Î±", "Est Î²"])
        
        # Display correlation values as text
        for i in 1:4, j in 1:4
            text!(ax8, i, j, text="$(round(corr_matrix[j,i], digits=2))", 
                  align=(:center, :center), fontsize=10,
                  color = abs(corr_matrix[j,i]) > 0.5 ? :white : :black)
        end
        
        Colorbar(fig[4, 3], hm, label="Correlation")
    end
    
    # Statistics summary text
    stats = analyze_recovery_results(experiment)
    if stats !== nothing
        Label(fig[1:2, 3], 
              "Statistics Summary\n\n" *
              "Success Rate: $(round(mean(experiment.estimation_success)*100, digits=1))%\n\n" *
              "Î± Recovery:\n" *
              "RÂ² = $(round(stats.alpha_stats.r2, digits=3))\n" *
              "MAE = $(round(stats.alpha_stats.mae, digits=3))\n" *
              "Bias = $(round(stats.alpha_stats.bias, digits=3))\n\n" *
              "Î² Recovery:\n" *
              "RÂ² = $(round(stats.beta_stats.r2, digits=3))\n" *
              "MAE = $(round(stats.beta_stats.mae, digits=3))\n" *
              "Bias = $(round(stats.beta_stats.bias, digits=3))",
              fontsize=11, halign=:left, valign=:top)
    end
    
    return fig
end

"""
çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
"""
function save_results_to_csv(experiment::ParameterRecoveryExperiment, filename::String="q_parameter_recovery_results.csv")
    df = DataFrame(
        subject_id = 1:experiment.n_subjects,
        true_alpha = experiment.true_alpha,
        true_beta = experiment.true_beta,
        estimated_alpha = experiment.estimated_alpha,
        estimated_beta = experiment.estimated_beta,
        log_likelihood = experiment.log_likelihoods,
        estimation_success = experiment.estimation_success,
        alpha_error = experiment.estimated_alpha - experiment.true_alpha,
        beta_error = experiment.estimated_beta - experiment.true_beta
    )
    
    CSV.write(filename, df)
    println("ğŸ“ çµæœã‚’ $filename ã«ä¿å­˜ã—ã¾ã—ãŸ")
    return df
end

"""
ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
"""
function main_parameter_recovery_experiment()
    println("ğŸš€ Qå­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å›å¾©å®Ÿé¨“é–‹å§‹")
    println("=" ^ 60)
    
    # å®Ÿé¨“å®Ÿè¡Œ
    experiment = run_parameter_recovery_experiment(1000, 4, 200)
    
    # åˆ†æ
    stats = analyze_recovery_results(experiment)
    
    # å¯è¦–åŒ–
    fig = create_recovery_visualization(experiment)
    
    # çµæœä¿å­˜
    df = save_results_to_csv(experiment)
    
    # å›³ã‚’ä¿å­˜
    save("q_parameter_recovery_visualization.png", fig, resolution=(1400, 1000))
    println("ğŸ¨ å¯è¦–åŒ–ã‚’ q_parameter_recovery_visualization.png ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    println("\nâœ… Qå­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å›å¾©å®Ÿé¨“å®Œäº†ï¼")
    
    return experiment, fig, df
end

# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
export ParameterRecoveryExperiment, run_parameter_recovery_experiment, 
       analyze_recovery_results, create_recovery_visualization,
       save_results_to_csv, main_parameter_recovery_experiment